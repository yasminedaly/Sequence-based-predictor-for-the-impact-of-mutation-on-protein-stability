{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8566efbd-4e24-46a3-a46b-c6f155223eb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8368b636-a109-4e7a-83f5-2920323aac08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.29.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages/PyYAML-6.0-py3.10-linux-x86_64.egg (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.5.5)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.22.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.4.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53d11f1f-8cdd-426a-b1d2-f17b9cb23eed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import Bio\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "import torch\n",
    "import math\n",
    "import esm\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98c273dd-2a79-4cf1-9073-c36cc5ab5d97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch.nn.functional as F\n",
    "\n",
    "HIDDEN_UNITS_POS_CONTACT = 5\n",
    "\n",
    "class ESMForSingleMutationPosOuter(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super().__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.fc1 = nn.Linear(self.model.config.hidden_size * 2, HIDDEN_UNITS_POS_CONTACT)\n",
    "        self.fc2 = nn.Linear(HIDDEN_UNITS_POS_CONTACT, 1)\n",
    "\n",
    "    def forward(self, sequence1, sequence2, pos):\n",
    "        # Assuming sequence1 and sequence2 are tensors of token ids\n",
    "        # We don't need to use the tokenizer\n",
    "        \n",
    "        output1 = self.model(sequence1)\n",
    "        output2 = self.model(sequence2)\n",
    "\n",
    "        outputs1_pos = output1.last_hidden_state[:, pos + 1]\n",
    "        outputs2_pos = output2.last_hidden_state[:, pos + 1]\n",
    "\n",
    "        outputs_pos_concat = torch.cat((outputs1_pos, outputs2_pos), 2)\n",
    "        fc1_outputs = F.relu(self.fc1(outputs_pos_concat))\n",
    "        logits = self.fc2(fc1_outputs)\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a29894b5-390d-4f40-a463-568826b055be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer_name):\n",
    "        self.df = df\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence1 = ''.join(self.df.iloc[idx]['wt_seq'])[:1022]\n",
    "        sequence2 = ''.join(self.df.iloc[idx]['mut_seq'])[:1022]\n",
    "        pos = self.df.iloc[idx]['mutation_pos']\n",
    "        \n",
    "        token_ids1 = self.tokenizer(sequence1, return_tensors='pt', truncation=True, padding='max_length', max_length=1022)['input_ids']\n",
    "        token_ids2 = self.tokenizer(sequence2, return_tensors='pt', truncation=True, padding='max_length', max_length=1022)['input_ids']\n",
    "        \n",
    "        return token_ids1, token_ids2, pos, torch.unsqueeze(torch.FloatTensor([self.df.iloc[idx]['ddg']]), 0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44446119-beda-41f1-92fd-f7824b443107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25aec026-50b3-4d9d-9c62-238653689af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a0e9c0-33f7-413d-bf10-76c67872848d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f12723a-156a-4203-8899-95ff76fce3bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35a086cf-ae5a-49dc-800c-522b23df8478",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], []\n",
    "    model.train()\n",
    "    device = 'cuda:0'\n",
    "    for idx, batch in enumerate(training_loader):\n",
    "        input_ids1, input_ids2, pos, labels = batch            \n",
    "        input_ids1 = input_ids1[0].to(device)\n",
    "        input_ids2 = input_ids2[0].to(device)\n",
    "        pos=pos.to(device)\n",
    "        labels=labels.to(device)\n",
    "        logits = model(sequence1 = input_ids1, sequence2 = input_ids2, pos = pos).to(device)\n",
    "        loss = torch.nn.functional.mse_loss(logits, labels).to(device)\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += labels.size(0)\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=0.1\n",
    "        )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a563a3e-de4e-428b-bd5d-fcc8e67cdea6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define directory\n",
    "directory = 'weights/'\n",
    "\n",
    "# Create directory if it does not exist\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Now you can\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1afdc8bf-c834-4e2a-93b0-3ec7d796874f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model ESMForSingleMutationPosOuter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/esm2_t6_8M_UR50D were not used when initializing EsmModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing EsmModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EsmModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['esm.pooler.dense.weight', 'esm.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_340/1129028376.py:14: UserWarning: Using a target size (torch.Size([128, 1, 1])) that is different to the input size (torch.Size([1, 128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = torch.nn.functional.mse_loss(logits, labels).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss epoch: 0.14196304729686374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_340/1129028376.py:14: UserWarning: Using a target size (torch.Size([53, 1, 1])) that is different to the input size (torch.Size([1, 53, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = torch.nn.functional.mse_loss(logits, labels).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss epoch: 0.10878333113098566\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-5\n",
    "EPOCHS = 2\n",
    "device = 'cuda:0'\n",
    "\n",
    "models = ['ESMForSingleMutationPosOuter']\n",
    "\n",
    "\n",
    "\n",
    "full_df = pd.read_csv('https://storage.googleapis.com/indaba-data/train/train.csv')\n",
    "\n",
    "\n",
    "# Filter the DataFrame to keep only rows with positive 'ddg' values\n",
    "df_positive_ddg = full_df[full_df['ddg'] < 0]\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "df_positive_ddg_shuffled = df_positive_ddg.sample(frac=1, random_state=42)\n",
    "\n",
    "# Select the first 70K rows\n",
    "df_selected = df_positive_ddg_shuffled.head(70000)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Filter the DataFrame to keep only rows with positive 'ddg' values\n",
    "df_positive_ddg = full_df[full_df['ddg'] < 0]\n",
    "\n",
    "df_positive_ddg=pd.merge(df_positive_ddg, df_selected)\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "df_positive_ddg_shuffled = df_positive_ddg.sample(frac=1, random_state=42)\n",
    "\n",
    "# Select the first 70K rows\n",
    "df_selected = df_positive_ddg_shuffled.head(70000)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "full_df = full_df[full_df['ddg'] > 0]\n",
    "\n",
    "preds = {n:[] for n in models} \n",
    "true = [None]*5\n",
    "\n",
    "for model_name in models:\n",
    "    model_class = globals()[model_name]\n",
    "    print(f'Training model {model_name}')\n",
    "    train_df = full_df\n",
    "    train_ds = ProteinDataset(train_df,'facebook/esm2_t6_8M_UR50D')\n",
    "        \n",
    "    model = model_class('facebook/esm2_t6_8M_UR50D')                        \n",
    "    model.to(device) \n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n",
    "    training_loader = DataLoader(train_ds, batch_size=128, num_workers = 2, shuffle = True)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=lr, steps_per_epoch=len(training_loader), epochs=EPOCHS)\n",
    "        \n",
    "    for epoch in range(EPOCHS):\n",
    "        train(epoch)\n",
    "         \n",
    "    model.to('cpu')\n",
    "    \n",
    "    torch.save(model, 'weights/' + model_name)\n",
    "    \n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4295f263-acbf-4852-9c2a-cacc1e23adde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "498ca78b-d846-46c5-a5a3-461b4c39dbb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>pdb_id</th>\n",
       "      <th>mutation</th>\n",
       "      <th>wt_aa</th>\n",
       "      <th>mutation_pos</th>\n",
       "      <th>mut_aa</th>\n",
       "      <th>wt_seq</th>\n",
       "      <th>mut_seq</th>\n",
       "      <th>ddg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1GYZ</td>\n",
       "      <td>W1Q</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>Q</td>\n",
       "      <td>WIARINAAVRAYGLNYSTFINGLKKAGIELDRKILADMAVRDPQAF...</td>\n",
       "      <td>QIARINAAVRAYGLNYSTFINGLKKAGIELDRKILADMAVRDPQAF...</td>\n",
       "      <td>0.228775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1GYZ</td>\n",
       "      <td>W1E</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>WIARINAAVRAYGLNYSTFINGLKKAGIELDRKILADMAVRDPQAF...</td>\n",
       "      <td>EIARINAAVRAYGLNYSTFINGLKKAGIELDRKILADMAVRDPQAF...</td>\n",
       "      <td>0.496896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1GYZ</td>\n",
       "      <td>W1N</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>WIARINAAVRAYGLNYSTFINGLKKAGIELDRKILADMAVRDPQAF...</td>\n",
       "      <td>NIARINAAVRAYGLNYSTFINGLKKAGIELDRKILADMAVRDPQAF...</td>\n",
       "      <td>0.163002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1GYZ</td>\n",
       "      <td>W1H</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>WIARINAAVRAYGLNYSTFINGLKKAGIELDRKILADMAVRDPQAF...</td>\n",
       "      <td>HIARINAAVRAYGLNYSTFINGLKKAGIELDRKILADMAVRDPQAF...</td>\n",
       "      <td>0.209013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1GYZ</td>\n",
       "      <td>W1D</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>WIARINAAVRAYGLNYSTFINGLKKAGIELDRKILADMAVRDPQAF...</td>\n",
       "      <td>DIARINAAVRAYGLNYSTFINGLKKAGIELDRKILADMAVRDPQAF...</td>\n",
       "      <td>0.407602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339753</th>\n",
       "      <td>339753</td>\n",
       "      <td>r7-562-TrROS-Hall</td>\n",
       "      <td>K47I</td>\n",
       "      <td>K</td>\n",
       "      <td>47</td>\n",
       "      <td>I</td>\n",
       "      <td>MKKYKITVYDEKTGEKHTIEIEMSEEELEELAKKLAEKHNVKVRIEKV</td>\n",
       "      <td>MKKYKITVYDEKTGEKHTIEIEMSEEELEELAKKLAEKHNVKVRIEIV</td>\n",
       "      <td>0.659345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339756</th>\n",
       "      <td>339756</td>\n",
       "      <td>r7-562-TrROS-Hall</td>\n",
       "      <td>K47F</td>\n",
       "      <td>K</td>\n",
       "      <td>47</td>\n",
       "      <td>F</td>\n",
       "      <td>MKKYKITVYDEKTGEKHTIEIEMSEEELEELAKKLAEKHNVKVRIEKV</td>\n",
       "      <td>MKKYKITVYDEKTGEKHTIEIEMSEEELEELAKKLAEKHNVKVRIEFV</td>\n",
       "      <td>0.077370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339757</th>\n",
       "      <td>339757</td>\n",
       "      <td>r7-562-TrROS-Hall</td>\n",
       "      <td>K47P</td>\n",
       "      <td>K</td>\n",
       "      <td>47</td>\n",
       "      <td>P</td>\n",
       "      <td>MKKYKITVYDEKTGEKHTIEIEMSEEELEELAKKLAEKHNVKVRIEKV</td>\n",
       "      <td>MKKYKITVYDEKTGEKHTIEIEMSEEELEELAKKLAEKHNVKVRIEPV</td>\n",
       "      <td>0.141990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339758</th>\n",
       "      <td>339758</td>\n",
       "      <td>r7-562-TrROS-Hall</td>\n",
       "      <td>K47C</td>\n",
       "      <td>K</td>\n",
       "      <td>47</td>\n",
       "      <td>C</td>\n",
       "      <td>MKKYKITVYDEKTGEKHTIEIEMSEEELEELAKKLAEKHNVKVRIEKV</td>\n",
       "      <td>MKKYKITVYDEKTGEKHTIEIEMSEEELEELAKKLAEKHNVKVRIECV</td>\n",
       "      <td>0.148234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339772</th>\n",
       "      <td>339772</td>\n",
       "      <td>r7-562-TrROS-Hall</td>\n",
       "      <td>V48I</td>\n",
       "      <td>V</td>\n",
       "      <td>48</td>\n",
       "      <td>I</td>\n",
       "      <td>MKKYKITVYDEKTGEKHTIEIEMSEEELEELAKKLAEKHNVKVRIEKV</td>\n",
       "      <td>MKKYKITVYDEKTGEKHTIEIEMSEEELEELAKKLAEKHNVKVRIEKI</td>\n",
       "      <td>0.077375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72245 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID             pdb_id mutation wt_aa  mutation_pos mut_aa   \n",
       "0            0               1GYZ      W1Q     W             1      Q  \\\n",
       "1            1               1GYZ      W1E     W             1      E   \n",
       "2            2               1GYZ      W1N     W             1      N   \n",
       "3            3               1GYZ      W1H     W             1      H   \n",
       "4            4               1GYZ      W1D     W             1      D   \n",
       "...        ...                ...      ...   ...           ...    ...   \n",
       "339753  339753  r7-562-TrROS-Hall     K47I     K            47      I   \n",
       "339756  339756  r7-562-TrROS-Hall     K47F     K            47      F   \n",
       "339757  339757  r7-562-TrROS-Hall     K47P     K            47      P   \n",
       "339758  339758  r7-562-TrROS-Hall     K47C     K            47      C   \n",
       "339772  339772  r7-562-TrROS-Hall     V48I     V            48      I   \n",
       "\n",
       "                                                   wt_seq   \n",
       "0       WIARINAAVRAYGLNYSTFINGLKKAGIELDRKILADMAVRDPQAF...  \\\n",
       "1       WIARINAAVRAYGLNYSTFINGLKKAGIELDRKILADMAVRDPQAF...   \n",
       "2       WIARINAAVRAYGLNYSTFINGLKKAGIELDRKILADMAVRDPQAF...   \n",
       "3       WIARINAAVRAYGLNYSTFINGLKKAGIELDRKILADMAVRDPQAF...   \n",
       "4       WIARINAAVRAYGLNYSTFINGLKKAGIELDRKILADMAVRDPQAF...   \n",
       "...                                                   ...   \n",
       "339753   MKKYKITVYDEKTGEKHTIEIEMSEEELEELAKKLAEKHNVKVRIEKV   \n",
       "339756   MKKYKITVYDEKTGEKHTIEIEMSEEELEELAKKLAEKHNVKVRIEKV   \n",
       "339757   MKKYKITVYDEKTGEKHTIEIEMSEEELEELAKKLAEKHNVKVRIEKV   \n",
       "339758   MKKYKITVYDEKTGEKHTIEIEMSEEELEELAKKLAEKHNVKVRIEKV   \n",
       "339772   MKKYKITVYDEKTGEKHTIEIEMSEEELEELAKKLAEKHNVKVRIEKV   \n",
       "\n",
       "                                                  mut_seq       ddg  \n",
       "0       QIARINAAVRAYGLNYSTFINGLKKAGIELDRKILADMAVRDPQAF...  0.228775  \n",
       "1       EIARINAAVRAYGLNYSTFINGLKKAGIELDRKILADMAVRDPQAF...  0.496896  \n",
       "2       NIARINAAVRAYGLNYSTFINGLKKAGIELDRKILADMAVRDPQAF...  0.163002  \n",
       "3       HIARINAAVRAYGLNYSTFINGLKKAGIELDRKILADMAVRDPQAF...  0.209013  \n",
       "4       DIARINAAVRAYGLNYSTFINGLKKAGIELDRKILADMAVRDPQAF...  0.407602  \n",
       "...                                                   ...       ...  \n",
       "339753   MKKYKITVYDEKTGEKHTIEIEMSEEELEELAKKLAEKHNVKVRIEIV  0.659345  \n",
       "339756   MKKYKITVYDEKTGEKHTIEIEMSEEELEELAKKLAEKHNVKVRIEFV  0.077370  \n",
       "339757   MKKYKITVYDEKTGEKHTIEIEMSEEELEELAKKLAEKHNVKVRIEPV  0.141990  \n",
       "339758   MKKYKITVYDEKTGEKHTIEIEMSEEELEELAKKLAEKHNVKVRIECV  0.148234  \n",
       "339772   MKKYKITVYDEKTGEKHTIEIEMSEEELEELAKKLAEKHNVKVRIEKI  0.077375  \n",
       "\n",
       "[72245 rows x 9 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66e7dcf-3425-41c9-bed7-ab7e0f705d23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
